{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206e9967",
   "metadata": {},
   "source": [
    "# 1. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e75fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4d3ad",
   "metadata": {},
   "source": [
    "# 2. Load the data \n",
    "We are provided with the training and test datasets as below: \\\n",
    "Training: \"olid-training-v1.0.tsv\" is the original dataset which contains the tweets and their labels for each subtask. We will be using subtask_a and other columns are discarded here.\\\n",
    "Testing: \"testset-levela.tsv\" is the test set we will be using for testing our model. This dataset contains the tweets to test the model trained on subtask_a. This dataset doesnâ€™t contain the labels for the tweets and is provided in a different file names \"labels-levela.csv\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41409b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86426</th>\n",
       "      <th>@USER She should ask a few native Americans what their take on this is.</th>\n",
       "      <th>OFF</th>\n",
       "      <th>UNT</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90194</th>\n",
       "      <th>@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL</th>\n",
       "      <th>OFF</th>\n",
       "      <th>TIN</th>\n",
       "      <th>IND</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16820</th>\n",
       "      <th>Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT</th>\n",
       "      <th>NOT</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62688</th>\n",
       "      <th>@USER Someone should'veTaken\" this piece of shit to a volcano. ðŸ˜‚\"</th>\n",
       "      <th>OFF</th>\n",
       "      <th>UNT</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43605</th>\n",
       "      <th>@USER @USER Obama wanted liberals &amp;amp; illegals to move into red states</th>\n",
       "      <th>NOT</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(86426, @USER She should ask a few native Americans what their take on this is., OFF, UNT, nan), (90194, @USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL, OFF, TIN, IND), (16820, Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT, NOT, nan, nan), (62688, @USER Someone should'veTaken\" this piece of shit to a volcano. ðŸ˜‚\", OFF, UNT, nan), (43605, @USER @USER Obama wanted liberals &amp; illegals to move into red states, NOT, nan, nan)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tsv = pd.read_table('olid-training-v1.0.tsv', sep='\\t',index_col=['id', 'tweet', 'subtask_a', 'subtask_b', 'subtask_c'])\n",
    "train_tsv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aced935f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully made csv file\n"
     ]
    }
   ],
   "source": [
    "#Convert .tsv to .csv format\n",
    "train_tsv.to_csv('train_csv',index=True)\n",
    "print(\"Successfully made csv file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c979b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b8869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13240 entries, 0 to 13239\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         13240 non-null  int64 \n",
      " 1   tweet      13240 non-null  object\n",
      " 2   subtask_a  13240 non-null  object\n",
      " 3   subtask_b  4400 non-null   object\n",
      " 4   subtask_c  3876 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 517.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca301d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a\n",
       "0      @USER She should ask a few native Americans wh...       OFF\n",
       "1      @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF\n",
       "2      Amazon is investigating Chinese employees who ...       NOT\n",
       "3      @USER Someone should'veTaken\" this piece of sh...       OFF\n",
       "4      @USER @USER Obama wanted liberals &amp; illega...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  @USER Sometimes I get strong vibes from people...       OFF\n",
       "13236  Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...       NOT\n",
       "13237  @USER And why report this garbage.  We don't g...       OFF\n",
       "13238                                        @USER Pussy       OFF\n",
       "13239  #Spanishrevenge vs. #justice #HumanRights and ...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the unwanted columns/variables\n",
    "df1 = df.drop(['id','subtask_b','subtask_c'],axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062bff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns=({'tweet':'tweet','subtask_a':'label'}),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ebffde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  @USER She should ask a few native Americans wh...   OFF\n",
       "1  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...   OFF\n",
       "2  Amazon is investigating Chinese employees who ...   NOT\n",
       "3  @USER Someone should'veTaken\" this piece of sh...   OFF\n",
       "4  @USER @USER Obama wanted liberals &amp; illega...   NOT"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f811d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13240 entries, 0 to 13239\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   13240 non-null  object\n",
      " 1   label   13240 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 207.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ceaf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  @USER She should ask a few native Americans wh...   OFF\n",
       "1  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...   OFF\n",
       "2  Amazon is investigating Chinese employees who ...   NOT\n",
       "3  @USER Someone should'veTaken\" this piece of sh...   OFF\n",
       "4  @USER @USER Obama wanted liberals &amp; illega...   NOT"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df1\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b30a3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15923</td>\n",
       "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27014</td>\n",
       "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30530</td>\n",
       "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13876</td>\n",
       "      <td>#Watching #Boomer getting the news that she is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60133</td>\n",
       "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...\n",
       "1  27014  #ConstitutionDay is revered by Conservatives, ...\n",
       "2  30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...\n",
       "3  13876  #Watching #Boomer getting the news that she is...\n",
       "4  60133  #NoPasaran: Unity demo to oppose the far-right..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_tsv = pd.read_table('testset-levela.tsv',sep='\\t')\n",
    "test1_tsv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a35d489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully made csv file\n"
     ]
    }
   ],
   "source": [
    "test1_tsv.to_csv('test1_csv',index=False)\n",
    "print(\"Successfully made csv file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f38b495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15923</td>\n",
       "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27014</td>\n",
       "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30530</td>\n",
       "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13876</td>\n",
       "      <td>#Watching #Boomer getting the news that she is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60133</td>\n",
       "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>73439</td>\n",
       "      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>25657</td>\n",
       "      <td>#MeetTheSpeakers ðŸ™Œ @USER will present in our e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>67018</td>\n",
       "      <td>3 people just unfollowed me for talking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>50665</td>\n",
       "      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>24583</td>\n",
       "      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>860 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet\n",
       "0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...\n",
       "1    27014  #ConstitutionDay is revered by Conservatives, ...\n",
       "2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...\n",
       "3    13876  #Watching #Boomer getting the news that she is...\n",
       "4    60133  #NoPasaran: Unity demo to oppose the far-right...\n",
       "..     ...                                                ...\n",
       "855  73439  #DespicableDems lie again about rifles. Dem Di...\n",
       "856  25657  #MeetTheSpeakers ðŸ™Œ @USER will present in our e...\n",
       "857  67018  3 people just unfollowed me for talking about ...\n",
       "858  50665  #WednesdayWisdom Antifa calls the right fascis...\n",
       "859  24583      #Kavanaugh typical #liberals , #Democrats URL\n",
       "\n",
       "[860 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.read_csv('test1_csv')\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4847d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15923</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27014</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30530</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13876</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60133</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>73439</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>25657</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>67018</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>50665</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>24583</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>860 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id label\n",
       "0    15923   OFF\n",
       "1    27014   NOT\n",
       "2    30530   NOT\n",
       "3    13876   NOT\n",
       "4    60133   OFF\n",
       "..     ...   ...\n",
       "855  73439   OFF\n",
       "856  25657   NOT\n",
       "857  67018   OFF\n",
       "858  50665   NOT\n",
       "859  24583   NOT\n",
       "\n",
       "[860 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_csv = pd.read_csv('labels-levela.csv',header=None)\n",
    "test2_csv.columns = ['id','label']\n",
    "test2_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ade805a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15923</td>\n",
       "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27014</td>\n",
       "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30530</td>\n",
       "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13876</td>\n",
       "      <td>#Watching #Boomer getting the news that she is...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60133</td>\n",
       "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>73439</td>\n",
       "      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>25657</td>\n",
       "      <td>#MeetTheSpeakers ðŸ™Œ @USER will present in our e...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>67018</td>\n",
       "      <td>3 people just unfollowed me for talking about ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>50665</td>\n",
       "      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>24583</td>\n",
       "      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>860 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet label\n",
       "0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   OFF\n",
       "1    27014  #ConstitutionDay is revered by Conservatives, ...   NOT\n",
       "2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...   NOT\n",
       "3    13876  #Watching #Boomer getting the news that she is...   NOT\n",
       "4    60133  #NoPasaran: Unity demo to oppose the far-right...   OFF\n",
       "..     ...                                                ...   ...\n",
       "855  73439  #DespicableDems lie again about rifles. Dem Di...   OFF\n",
       "856  25657  #MeetTheSpeakers ðŸ™Œ @USER will present in our e...   NOT\n",
       "857  67018  3 people just unfollowed me for talking about ...   OFF\n",
       "858  50665  #WednesdayWisdom Antifa calls the right fascis...   NOT\n",
       "859  24583      #Kavanaugh typical #liberals , #Democrats URL   NOT\n",
       "\n",
       "[860 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pd.merge(test1,test2_csv,on='id', how='inner')\n",
    "test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aec7551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Watching #Boomer getting the news that she is...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>#MeetTheSpeakers ðŸ™Œ @USER will present in our e...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>3 people just unfollowed me for talking about ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>860 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet label\n",
       "0    #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   OFF\n",
       "1    #ConstitutionDay is revered by Conservatives, ...   NOT\n",
       "2    #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...   NOT\n",
       "3    #Watching #Boomer getting the news that she is...   NOT\n",
       "4    #NoPasaran: Unity demo to oppose the far-right...   OFF\n",
       "..                                                 ...   ...\n",
       "855  #DespicableDems lie again about rifles. Dem Di...   OFF\n",
       "856  #MeetTheSpeakers ðŸ™Œ @USER will present in our e...   NOT\n",
       "857  3 people just unfollowed me for talking about ...   OFF\n",
       "858  #WednesdayWisdom Antifa calls the right fascis...   NOT\n",
       "859      #Kavanaugh typical #liberals , #Democrats URL   NOT\n",
       "\n",
       "[860 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test_csv.drop('id', axis =1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "657bcaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  @USER She should ask a few native Americans wh...   OFF\n",
       "1  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...   OFF\n",
       "2  Amazon is investigating Chinese employees who ...   NOT\n",
       "3  @USER Someone should'veTaken\" this piece of sh...   OFF\n",
       "4  @USER @USER Obama wanted liberals &amp; illega...   NOT"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "078a46a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13240 entries, 0 to 13239\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   13240 non-null  object\n",
      " 1   label   13240 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 207.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aaff6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 860 entries, 0 to 859\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   860 non-null    object\n",
      " 1   label   860 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 20.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea22f0",
   "metadata": {},
   "source": [
    "# 3. Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e27367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords, @USER words, emojis, ...\n",
    "#change the tweets into lower case\n",
    "# tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcb722f3",
   "metadata": {},
   "outputs": [],
   "source": [
    " from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f17b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f18e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "    tempArr = []\n",
    "    for line in df:\n",
    "        # send to tweet_processor\n",
    "        tmpL = p.clean(line)\n",
    "        # remove puctuation\n",
    "        tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "        tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "        tempArr.append(tmpL)\n",
    "    return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e47b5ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>she should ask a few native americans what the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>go home youre drunk url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>someone shouldvetaken this piece of shit to a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>obama wanted liberals &amp;amp illegals to move in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label  \\\n",
       "0  @USER She should ask a few native Americans wh...   OFF   \n",
       "1  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...   OFF   \n",
       "2  Amazon is investigating Chinese employees who ...   NOT   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...   OFF   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...   NOT   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  she should ask a few native americans what the...  \n",
       "1                            go home youre drunk url  \n",
       "2  amazon is investigating chinese employees who ...  \n",
       "3  someone shouldvetaken this piece of shit to a ...  \n",
       "4  obama wanted liberals &amp illegals to move in...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean training data\n",
    "train_tweet = clean_tweets(train[\"tweet\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)\n",
    "# append cleaned tweets to the training data\n",
    "train[\"clean_tweet\"] = train_tweet\n",
    "# compare the cleaned and uncleaned tweets\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d22c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she should ask a few native americans what the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go home youre drunk url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>someone shouldvetaken this piece of shit to a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama wanted liberals &amp;amp illegals to move in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>liberals are all kookoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oh noes tough shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>was literally just talking about this lol all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>buy more icecream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>canada doesnt need another cuck we already hav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  she should ask a few native americans what the...\n",
       "1                            go home youre drunk url\n",
       "2  amazon is investigating chinese employees who ...\n",
       "3  someone shouldvetaken this piece of shit to a ...\n",
       "4  obama wanted liberals &amp illegals to move in...\n",
       "5                           liberals are all kookoo \n",
       "6                                 oh noes tough shit\n",
       "7  was literally just talking about this lol all ...\n",
       "8                                  buy more icecream\n",
       "9  canada doesnt need another cuck we already hav..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0565fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>democrats support antifa muslim brotherhood ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>is revered by conservatives hated by progressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>first it reduces the ca url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Watching #Boomer getting the news that she is...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>getting the news that she is still up for paro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>unity demo to oppose the far right in enough ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label  \\\n",
       "0  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   OFF   \n",
       "1  #ConstitutionDay is revered by Conservatives, ...   NOT   \n",
       "2  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...   NOT   \n",
       "3  #Watching #Boomer getting the news that she is...   NOT   \n",
       "4  #NoPasaran: Unity demo to oppose the far-right...   OFF   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  democrats support antifa muslim brotherhood ms...  \n",
       "1  is revered by conservatives hated by progressi...  \n",
       "2                        first it reduces the ca url  \n",
       "3  getting the news that she is still up for paro...  \n",
       "4   unity demo to oppose the far right in enough ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean testing data\n",
    "test_tweet = clean_tweets(test[\"tweet\"])\n",
    "test_tweet = pd.DataFrame(test_tweet)\n",
    "# append cleaned tweets to the training data\n",
    "test[\"clean_tweet\"] = test_tweet\n",
    "# compare the cleaned and uncleaned tweets\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2f5bfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>democrats support antifa muslim brotherhood ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is revered by conservatives hated by progressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first it reduces the ca url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>getting the news that she is still up for paro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unity demo to oppose the far right in enough ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  democrats support antifa muslim brotherhood ms...\n",
       "1  is revered by conservatives hated by progressi...\n",
       "2                        first it reduces the ca url\n",
       "3  getting the news that she is still up for paro...\n",
       "4   unity demo to oppose the far right in enough ..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b129631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e98cd781",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['clean_tweet']\n",
    "X_test = test['clean_tweet']\n",
    "y_train = train['label'].replace(['NOT','OFF'],[0,1]).values\n",
    "y_test = test['label'].replace(['NOT','OFF'],[0,1]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b6ffa3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8681d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the tokens to convert into numerical form\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52810a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original text is:\n",
      "\n",
      "[\"This is Import Data's Youtube channel\", 'Data science is my passion and it is fun!', 'Please subscribe to my channel']\n",
      "\n",
      "The exctracted tokens are:\n",
      "\n",
      "['channel', 'data', 'fun', 'import', 'passion', 'science', 'subscribe', 'youtube']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>data</th>\n",
       "      <th>fun</th>\n",
       "      <th>import</th>\n",
       "      <th>passion</th>\n",
       "      <th>science</th>\n",
       "      <th>subscribe</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   channel  data  fun  import  passion  science  subscribe  youtube\n",
       "0        1     1    0       1        0        0          0        1\n",
       "1        0     1    1       0        1        1          0        0\n",
       "2        1     0    0       0        0        0          1        0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"This is Import Data's Youtube channel\",\n",
    "             \"Data science is my passion and it is fun!\",\n",
    "             \"Please subscribe to my channel\"]\n",
    "\n",
    "# initializing the countvectorizer\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "# tokenize and make the document into a matrix\n",
    "document_term_matrix = vectorizer.fit_transform(documents)\n",
    "print(f'The original text is:\\n')\n",
    "print(documents)\n",
    "features = vectorizer.get_feature_names()\n",
    "print(f'\\nThe exctracted tokens are:\\n')\n",
    "print(features)\n",
    "# check the result\n",
    "pd.DataFrame(document_term_matrix.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bf52e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorize tweets for model building\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(X_train) + list(X_test))\n",
    "\n",
    "# transform documents to document-term matrix\n",
    "X_train_vec = vectorizer.transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a68684ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13240, 18864)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c040c",
   "metadata": {},
   "source": [
    "# 4. ML Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3894ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf6e897",
   "metadata": {},
   "source": [
    "# 4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8cc713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       620\n",
      "           1       0.74      0.44      0.55       240\n",
      "\n",
      "    accuracy                           0.80       860\n",
      "   macro avg       0.77      0.69      0.71       860\n",
      "weighted avg       0.79      0.80      0.78       860\n",
      "\n",
      "Confusion matrix \n",
      " [[582  38]\n",
      " [134 106]]\n",
      "\n",
      " Logistic Regression, Accuracy Score: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishaduwadi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_fit = lr.fit(X_train_vec,y_train)\n",
    "y_pred_lr = lr.predict(X_test_vec)\n",
    "report = classification_report(y_test, y_pred_lr)\n",
    "matrix = confusion_matrix(y_test,y_pred_lr)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc1=accuracy_score(y_test,y_pred_lr)\n",
    "\n",
    "print(\"\\n Logistic Regression, Accuracy Score:\" , acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "592edc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "479e6076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, Grid search best parameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "grid_params_lr = dict(\n",
    "    solver=['newton-cg', 'liblinear'],\n",
    "    penalty=['l2'],\n",
    "    C=[10, 1.0, 0.1])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(), param_grid=grid_params_lr, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_lr.fit(X_train_vec, y_train)\n",
    "\n",
    "print(\"Logistic Regression, Grid search best parameters:\", grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "031bd8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       620\n",
      "           1       0.74      0.44      0.55       240\n",
      "\n",
      "    accuracy                           0.80       860\n",
      "   macro avg       0.77      0.69      0.71       860\n",
      "weighted avg       0.79      0.80      0.78       860\n",
      "\n",
      "Confusion matrix \n",
      " [[582  38]\n",
      " [134 106]]\n",
      "\n",
      " Logistic Regression Grid search, Accuracy Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "grid_pred_lr = grid_search_lr.predict(X_test_vec)\n",
    "report = classification_report(y_test, grid_pred_lr)\n",
    "matrix = confusion_matrix(y_test,grid_pred_lr)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc1_g=accuracy_score(y_test,grid_pred_lr)\n",
    "\n",
    "print(\"\\n Logistic Regression Grid search, Accuracy Score:\" , acc1_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eddaae",
   "metadata": {},
   "source": [
    "# 4.2. Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41dbaf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       620\n",
      "           1       0.63      0.46      0.53       240\n",
      "\n",
      "    accuracy                           0.77       860\n",
      "   macro avg       0.72      0.68      0.69       860\n",
      "weighted avg       0.76      0.77      0.76       860\n",
      "\n",
      "Confusion matrix \n",
      " [[556  64]\n",
      " [130 110]]\n",
      "\n",
      " Ridge Classifier, Accuracy Score: 0.7744186046511627\n"
     ]
    }
   ],
   "source": [
    "rc = RidgeClassifier()\n",
    "rc_fit = rc.fit(X_train_vec,y_train)\n",
    "y_pred_rc = rc.predict(X_test_vec)\n",
    "report = classification_report(y_test, y_pred_rc)\n",
    "matrix = confusion_matrix(y_test,y_pred_rc)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc2=accuracy_score(y_test,y_pred_rc)\n",
    "\n",
    "print(\"\\n Ridge Classifier, Accuracy Score:\" , acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f41a13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Classifier - Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c161933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, Grid search best parameters: {'alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "grid_params_rc = dict(alpha=[0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "grid_search_rc = GridSearchCV(RidgeClassifier(), param_grid=grid_params_rc, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_rc.fit(X_train_vec, y_train)\n",
    "\n",
    "print(\"Logistic Regression, Grid search best parameters:\", grid_search_rc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d76069ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       620\n",
      "           1       0.58      0.48      0.53       240\n",
      "\n",
      "    accuracy                           0.76       860\n",
      "   macro avg       0.70      0.67      0.68       860\n",
      "weighted avg       0.75      0.76      0.75       860\n",
      "\n",
      "Confusion matrix \n",
      " [[538  82]\n",
      " [125 115]]\n",
      "\n",
      " Ridge Classifier Grid search, Accuracy Score: 0.7593023255813953\n"
     ]
    }
   ],
   "source": [
    "grid_pred_rc = grid_search_rc.predict(X_test_vec)\n",
    "report = classification_report(y_test, grid_pred_rc)\n",
    "matrix = confusion_matrix(y_test,grid_pred_rc)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc2_g=accuracy_score(y_test,grid_pred_rc)\n",
    "\n",
    "print(\"\\n Ridge Classifier Grid search, Accuracy Score:\" , acc2_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8e342",
   "metadata": {},
   "source": [
    "# 4.3. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3b5cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88       620\n",
      "           1       0.89      0.33      0.48       240\n",
      "\n",
      "    accuracy                           0.80       860\n",
      "   macro avg       0.84      0.66      0.68       860\n",
      "weighted avg       0.82      0.80      0.77       860\n",
      "\n",
      "Confusion matrix \n",
      " [[610  10]\n",
      " [160  80]]\n",
      "\n",
      " Support Vector Machine, Accuracy Score: 0.8023255813953488\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC()\n",
    "svm_fit = svm.fit(X_train_vec,y_train)\n",
    "y_pred_svm = svm.predict(X_test_vec)\n",
    "report = classification_report(y_test, y_pred_svm)\n",
    "matrix = confusion_matrix(y_test,y_pred_svm)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc3=accuracy_score(y_test,y_pred_svm)\n",
    "\n",
    "print(\"\\n Support Vector Machine, Accuracy Score:\" , acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b85b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f57154ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  11.8s\n",
      "[CV 2/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  11.3s\n",
      "[CV 3/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  12.3s\n",
      "[CV 4/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  13.1s\n",
      "[CV 5/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  12.0s\n",
      "[CV 1/5] END ................C=0.1, gamma=0.1, kernel=linear; total time=   9.7s\n",
      "[CV 2/5] END ................C=0.1, gamma=0.1, kernel=linear; total time=   9.1s\n",
      "[CV 3/5] END ................C=0.1, gamma=0.1, kernel=linear; total time=   9.0s\n",
      "[CV 4/5] END ................C=0.1, gamma=0.1, kernel=linear; total time=   8.9s\n",
      "[CV 5/5] END ................C=0.1, gamma=0.1, kernel=linear; total time=   8.9s\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  10.0s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  10.1s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   9.8s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   9.5s\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   9.4s\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.01, kernel=linear; total time=   8.6s\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.01, kernel=linear; total time=   8.6s\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.01, kernel=linear; total time=   8.5s\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.01, kernel=linear; total time=   8.6s\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.01, kernel=linear; total time=   8.6s\n",
      "[CV 1/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   8.6s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   8.7s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   8.6s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   9.0s\n",
      "[CV 5/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   8.9s\n",
      "[CV 1/5] END ..............C=0.1, gamma=0.001, kernel=linear; total time=   9.2s\n",
      "[CV 2/5] END ..............C=0.1, gamma=0.001, kernel=linear; total time=   9.9s\n",
      "[CV 3/5] END ..............C=0.1, gamma=0.001, kernel=linear; total time=   9.2s\n",
      "[CV 4/5] END ..............C=0.1, gamma=0.001, kernel=linear; total time=   8.6s\n",
      "[CV 5/5] END ..............C=0.1, gamma=0.001, kernel=linear; total time=   8.8s\n",
      "[CV 1/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  16.5s\n",
      "[CV 2/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  15.7s\n",
      "[CV 3/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  16.3s\n",
      "[CV 4/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  16.5s\n",
      "[CV 5/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  16.7s\n",
      "[CV 1/5] END ..................C=1, gamma=0.1, kernel=linear; total time=  12.8s\n",
      "[CV 2/5] END ..................C=1, gamma=0.1, kernel=linear; total time=  12.6s\n",
      "[CV 3/5] END ..................C=1, gamma=0.1, kernel=linear; total time=  12.9s\n",
      "[CV 4/5] END ..................C=1, gamma=0.1, kernel=linear; total time=  11.8s\n",
      "[CV 5/5] END ..................C=1, gamma=0.1, kernel=linear; total time=  12.1s\n",
      "[CV 1/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  10.7s\n",
      "[CV 2/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  10.8s\n",
      "[CV 3/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  11.2s\n",
      "[CV 4/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  11.2s\n",
      "[CV 5/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  11.0s\n",
      "[CV 1/5] END .................C=1, gamma=0.01, kernel=linear; total time=  12.4s\n",
      "[CV 2/5] END .................C=1, gamma=0.01, kernel=linear; total time=  12.4s\n",
      "[CV 3/5] END .................C=1, gamma=0.01, kernel=linear; total time=  13.0s\n",
      "[CV 4/5] END .................C=1, gamma=0.01, kernel=linear; total time=  12.1s\n",
      "[CV 5/5] END .................C=1, gamma=0.01, kernel=linear; total time=  12.8s\n",
      "[CV 1/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  10.3s\n",
      "[CV 2/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  10.0s\n",
      "[CV 3/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  10.2s\n",
      "[CV 4/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  10.5s\n",
      "[CV 5/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  10.3s\n",
      "[CV 1/5] END ................C=1, gamma=0.001, kernel=linear; total time=  12.2s\n",
      "[CV 2/5] END ................C=1, gamma=0.001, kernel=linear; total time=  12.5s\n",
      "[CV 3/5] END ................C=1, gamma=0.001, kernel=linear; total time=  12.6s\n",
      "[CV 4/5] END ................C=1, gamma=0.001, kernel=linear; total time=  13.1s\n",
      "[CV 5/5] END ................C=1, gamma=0.001, kernel=linear; total time=  12.8s\n",
      "[CV 1/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  30.6s\n",
      "[CV 2/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  31.3s\n",
      "[CV 3/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  31.4s\n",
      "[CV 4/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  32.0s\n",
      "[CV 5/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  30.4s\n",
      "[CV 1/5] END .................C=10, gamma=0.1, kernel=linear; total time=  15.2s\n",
      "[CV 2/5] END .................C=10, gamma=0.1, kernel=linear; total time=  16.9s\n",
      "[CV 3/5] END .................C=10, gamma=0.1, kernel=linear; total time=  16.3s\n",
      "[CV 4/5] END .................C=10, gamma=0.1, kernel=linear; total time=  15.4s\n",
      "[CV 5/5] END .................C=10, gamma=0.1, kernel=linear; total time=  15.9s\n",
      "[CV 1/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  11.1s\n",
      "[CV 2/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  11.3s\n",
      "[CV 3/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  10.9s\n",
      "[CV 4/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  11.3s\n",
      "[CV 5/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  11.6s\n",
      "[CV 1/5] END ................C=10, gamma=0.01, kernel=linear; total time=  14.9s\n",
      "[CV 2/5] END ................C=10, gamma=0.01, kernel=linear; total time=  17.4s\n",
      "[CV 3/5] END ................C=10, gamma=0.01, kernel=linear; total time=  16.8s\n",
      "[CV 4/5] END ................C=10, gamma=0.01, kernel=linear; total time=  15.5s\n",
      "[CV 5/5] END ................C=10, gamma=0.01, kernel=linear; total time=  15.2s\n",
      "[CV 1/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  10.8s\n",
      "[CV 2/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  10.4s\n",
      "[CV 3/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  10.1s\n",
      "[CV 4/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   9.3s\n",
      "[CV 5/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   9.2s\n",
      "[CV 1/5] END ...............C=10, gamma=0.001, kernel=linear; total time=  13.5s\n",
      "[CV 2/5] END ...............C=10, gamma=0.001, kernel=linear; total time=  14.4s\n",
      "[CV 3/5] END ...............C=10, gamma=0.001, kernel=linear; total time=  13.9s\n",
      "[CV 4/5] END ...............C=10, gamma=0.001, kernel=linear; total time=  13.5s\n",
      "[CV 5/5] END ...............C=10, gamma=0.001, kernel=linear; total time=  14.0s\n",
      "SVM, Grid search best parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range\n",
    "grid_param_svm = {'C': [0.1, 1, 10],\n",
    "              'gamma': [ 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf','linear' ]}                #'sigmoid',...\n",
    " \n",
    "grid_search_svm = GridSearchCV(svm, grid_param_svm, refit = True, verbose = 3)\n",
    " \n",
    "grid_search_svm.fit(X_train_vec, y_train)\n",
    "\n",
    "print(\"SVM, Grid search best parameters:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b84fcc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       620\n",
      "           1       0.77      0.45      0.57       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.80      0.70      0.73       860\n",
      "weighted avg       0.81      0.81      0.79       860\n",
      "\n",
      "Confusion matrix \n",
      " [[588  32]\n",
      " [131 109]]\n",
      "\n",
      " SVM Grid search, Accuracy Score: 0.8104651162790698\n"
     ]
    }
   ],
   "source": [
    "grid_pred_svm = grid_search_svm.predict(X_test_vec)\n",
    "report = classification_report(y_test, grid_pred_svm)\n",
    "matrix = confusion_matrix(y_test,grid_pred_svm)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc3_g=accuracy_score(y_test,grid_pred_svm)\n",
    "\n",
    "print(\"\\n SVM Grid search, Accuracy Score:\" , acc3_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25542241",
   "metadata": {},
   "source": [
    "# 4.4. K Nearest Neighbors (K-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27a51124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85       620\n",
      "           1       0.82      0.11      0.20       240\n",
      "\n",
      "    accuracy                           0.75       860\n",
      "   macro avg       0.78      0.55      0.52       860\n",
      "weighted avg       0.76      0.75      0.67       860\n",
      "\n",
      "Confusion matrix \n",
      " [[614   6]\n",
      " [213  27]]\n",
      "\n",
      " K Nearest Neighbors, Accuracy Score: 0.7453488372093023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "knn_fit = knn.fit(X_train_vec, y_train)\n",
    "y_pred_knn = knn.predict(X_test_vec)\n",
    "\n",
    "report = classification_report(y_test, y_pred_knn)\n",
    "matrix = confusion_matrix(y_test,y_pred_knn)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc4=accuracy_score(y_test,y_pred_knn)\n",
    "\n",
    "print(\"\\n K Nearest Neighbors, Accuracy Score:\" , acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ab188d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f48e8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Grid search best parameters: {'leaf_size': 5, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "grid_params_knn = {\n",
    "    'n_neighbors': [1, 3 , 5, 10],\n",
    "    'leaf_size': [5, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "                   \n",
    "# with GridSearch\n",
    "grid_search_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    grid_params_knn,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs = -1)\n",
    "\n",
    "grid_search_knn.fit(X_train_vec, y_train)\n",
    "\n",
    "print(\"SVM, Grid search best parameters:\", grid_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "261e9bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85       620\n",
      "           1       0.83      0.17      0.28       240\n",
      "\n",
      "    accuracy                           0.76       860\n",
      "   macro avg       0.79      0.58      0.57       860\n",
      "weighted avg       0.78      0.76      0.69       860\n",
      "\n",
      "Confusion matrix \n",
      " [[612   8]\n",
      " [200  40]]\n",
      "\n",
      " K-NN Grid search, Accuracy Score: 0.7581395348837209\n"
     ]
    }
   ],
   "source": [
    "grid_pred_knn = grid_search_knn.predict(X_test_vec)\n",
    "report = classification_report(y_test, grid_pred_knn)\n",
    "matrix = confusion_matrix(y_test,grid_pred_knn)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc4_g=accuracy_score(y_test,grid_pred_knn)\n",
    "\n",
    "print(\"\\n K-NN Grid search, Accuracy Score:\" , acc4_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214c359d",
   "metadata": {},
   "source": [
    "# 4.5. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bd28cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86       620\n",
      "           1       0.91      0.20      0.33       240\n",
      "\n",
      "    accuracy                           0.77       860\n",
      "   macro avg       0.83      0.60      0.59       860\n",
      "weighted avg       0.80      0.77      0.71       860\n",
      "\n",
      "Confusion matrix \n",
      " [[615   5]\n",
      " [192  48]]\n",
      "\n",
      " Decision Tree Classifier, Accuracy Score: 0.7709302325581395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree =DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=2)\n",
    "dtree.fit(X_train_vec,y_train)\n",
    "y_pred_dtree = dtree.predict(X_test_vec)\n",
    "\n",
    "report = classification_report(y_test, y_pred_dtree)\n",
    "matrix = confusion_matrix(y_test,y_pred_dtree)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc5=accuracy_score(y_test,y_pred_dtree)\n",
    "\n",
    "print(\"\\n Decision Tree Classifier, Accuracy Score:\" , acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8620868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc27797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree, Grid search best parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishaduwadi/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281\n",
      " 0.68897281 0.68897281 0.68897281        nan 0.68897281 0.68897281\n",
      " 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281\n",
      "        nan 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281\n",
      " 0.68897281 0.68897281 0.68897281        nan 0.68897281 0.68897281\n",
      " 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281\n",
      "        nan 0.69916918 0.69909366 0.69916918 0.69916918 0.69916918\n",
      " 0.69909366 0.69916918 0.69909366        nan 0.69916918 0.69916918\n",
      " 0.69916918 0.69909366 0.69916918 0.69916918 0.69916918 0.69916918\n",
      "        nan 0.69856495 0.69856495 0.69864048 0.69864048 0.69856495\n",
      " 0.69856495 0.69856495 0.69864048        nan 0.69879154 0.69871601\n",
      " 0.69871601 0.69879154 0.69871601 0.69879154 0.69879154 0.69879154\n",
      "        nan 0.70400302 0.70400302 0.70392749 0.70400302 0.70392749\n",
      " 0.70407855 0.70407855 0.70385196        nan 0.70400302 0.70392749\n",
      " 0.70392749 0.70400302 0.70400302 0.70392749 0.70407855 0.70385196\n",
      "        nan 0.70324773 0.70324773 0.70324773 0.70339879 0.70339879\n",
      " 0.70339879 0.70347432 0.70332326        nan 0.70362538 0.70362538\n",
      " 0.70362538 0.70362538 0.70362538 0.70362538 0.70362538 0.70362538\n",
      "        nan 0.7097432  0.7097432  0.7097432  0.7097432  0.7097432\n",
      " 0.7097432  0.7097432  0.7097432         nan 0.7097432  0.70959215\n",
      " 0.7097432  0.7097432  0.70966767 0.70966767 0.70981873 0.70981873\n",
      "        nan 0.7092145  0.7092145  0.7092145  0.7092145  0.7092145\n",
      " 0.7092145  0.70929003 0.70929003        nan 0.7097432  0.7097432\n",
      " 0.7097432  0.7097432  0.7097432  0.7097432  0.7097432  0.7097432\n",
      "        nan 0.71661631 0.71669184 0.71661631 0.71654079 0.71661631\n",
      " 0.71661631 0.71669184 0.71661631        nan 0.71646526 0.7163142\n",
      " 0.71638973 0.71623867 0.71646526 0.7163142  0.71661631 0.71654079\n",
      "        nan 0.71616314 0.71616314 0.71616314 0.71616314 0.71616314\n",
      " 0.71616314 0.71623867 0.71623867        nan 0.71676737 0.71676737\n",
      " 0.71676737 0.71676737 0.71676737 0.71676737 0.71676737 0.71676737\n",
      "        nan 0.72409366 0.72401813 0.7239426  0.72371601 0.72401813\n",
      " 0.72401813 0.72386707 0.7239426         nan 0.72371601 0.72333837\n",
      " 0.72371601 0.7234139  0.72364048 0.7234139  0.72371601 0.72401813\n",
      "        nan 0.72364048 0.72364048 0.72364048 0.72364048 0.72364048\n",
      " 0.72364048 0.72371601 0.72371601        nan 0.72409366 0.72409366\n",
      " 0.72409366 0.72409366 0.72409366 0.72424471 0.72409366 0.72424471\n",
      "        nan 0.72590634 0.72590634 0.72583082 0.72598187 0.7260574\n",
      " 0.72590634 0.72575529 0.72575529        nan 0.72507553 0.72484894\n",
      " 0.7255287  0.72454683 0.72560423 0.72507553 0.72567976 0.72537764\n",
      "        nan 0.72567976 0.72567976 0.72567976 0.72567976 0.72567976\n",
      " 0.72567976 0.72575529 0.72575529        nan 0.72635952 0.72628399\n",
      " 0.72628399 0.72643505 0.72628399 0.72628399 0.72620846 0.72613293\n",
      "        nan 0.72938066 0.72900302 0.72915408 0.72930514 0.72907855\n",
      " 0.72915408 0.72885196 0.72915408        nan 0.72809668 0.72794562\n",
      " 0.72756798 0.72802115 0.72839879 0.72862538 0.72824773 0.72794562\n",
      "        nan 0.72900302 0.72900302 0.72900302 0.72892749 0.72900302\n",
      " 0.72892749 0.72900302 0.72907855        nan 0.72953172 0.72960725\n",
      " 0.72953172 0.72953172 0.72960725 0.72945619 0.72953172 0.72953172\n",
      "        nan 0.73164653 0.731571   0.73194864 0.731571   0.73134441\n",
      " 0.73202417 0.73172205 0.731571          nan 0.7310423  0.73066465\n",
      " 0.73021148 0.73089124 0.73096677 0.73134441 0.73141994 0.73089124\n",
      "        nan 0.73187311 0.73179758 0.73179758 0.73179758 0.73187311\n",
      " 0.73179758 0.73187311 0.73187311        nan 0.73225076 0.73225076\n",
      " 0.73240181 0.73217523 0.73217523 0.73232628 0.73240181 0.73232628\n",
      "        nan 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281\n",
      " 0.68897281 0.68897281 0.68897281        nan 0.68897281 0.68897281\n",
      " 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281\n",
      "        nan 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281\n",
      " 0.68897281 0.68897281 0.68897281        nan 0.68897281 0.68897281\n",
      " 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281 0.68897281\n",
      "        nan 0.69909366 0.69909366 0.69916918 0.69916918 0.69916918\n",
      " 0.69916918 0.69916918 0.69909366        nan 0.69916918 0.69916918\n",
      " 0.69916918 0.69909366 0.69909366 0.69916918 0.69909366 0.69909366\n",
      "        nan 0.69864048 0.69864048 0.69856495 0.69856495 0.69856495\n",
      " 0.69864048 0.69856495 0.69864048        nan 0.69879154 0.69871601\n",
      " 0.69871601 0.69871601 0.69871601 0.69871601 0.69871601 0.69871601\n",
      "        nan 0.70377644 0.70370091 0.70370091 0.70370091 0.70377644\n",
      " 0.70377644 0.70392749 0.70385196        nan 0.70385196 0.70392749\n",
      " 0.70385196 0.70385196 0.70370091 0.70392749 0.70370091 0.70377644\n",
      "        nan 0.70324773 0.70309668 0.70324773 0.70309668 0.70324773\n",
      " 0.70324773 0.70332326 0.70317221        nan 0.70347432 0.70347432\n",
      " 0.70347432 0.70347432 0.70347432 0.70347432 0.70347432 0.70347432\n",
      "        nan 0.70936556 0.70944109 0.70944109 0.70936556 0.70936556\n",
      " 0.70944109 0.70936556 0.70944109        nan 0.70951662 0.70936556\n",
      " 0.70944109 0.70929003 0.70936556 0.70929003 0.70944109 0.70951662\n",
      "        nan 0.70891239 0.70891239 0.70891239 0.70891239 0.70891239\n",
      " 0.70891239 0.70898792 0.70898792        nan 0.70951662 0.70951662\n",
      " 0.70951662 0.70951662 0.70951662 0.70951662 0.70951662 0.70951662\n",
      "        nan 0.71601208 0.71623867 0.71623867 0.7163142  0.71646526\n",
      " 0.71616314 0.71646526 0.71638973        nan 0.71638973 0.71601208\n",
      " 0.71608761 0.71654079 0.71654079 0.71608761 0.71646526 0.71661631\n",
      "        nan 0.71608761 0.71608761 0.71608761 0.71608761 0.71608761\n",
      " 0.71608761 0.71616314 0.71608761        nan 0.71669184 0.71669184\n",
      " 0.71669184 0.71661631 0.71669184 0.71669184 0.71661631 0.71669184\n",
      "        nan 0.7239426  0.72409366 0.72386707 0.72386707 0.72401813\n",
      " 0.7239426  0.72424471 0.72401813        nan 0.72386707 0.72379154\n",
      " 0.72348943 0.7239426  0.72386707 0.72386707 0.72401813 0.72424471\n",
      "        nan 0.72364048 0.72364048 0.72364048 0.72364048 0.72364048\n",
      " 0.72364048 0.72371601 0.72371601        nan 0.72416918 0.72416918\n",
      " 0.72432024 0.72416918 0.72416918 0.72432024 0.72416918 0.72432024\n",
      "        nan 0.72620846 0.7260574  0.72590634 0.72583082 0.72620846\n",
      " 0.72598187 0.7260574  0.72613293        nan 0.72530211 0.72567976\n",
      " 0.72545317 0.72537764 0.72590634 0.72522659 0.72590634 0.72567976\n",
      "        nan 0.7255287  0.7255287  0.7255287  0.7255287  0.7255287\n",
      " 0.7255287  0.72560423 0.72560423        nan 0.72635952 0.72635952\n",
      " 0.72651057 0.72651057 0.72635952 0.72635952 0.72651057 0.72651057\n",
      "        nan 0.72907855 0.72915408 0.72922961 0.72938066 0.72885196\n",
      " 0.72900302 0.72885196 0.72922961        nan 0.72817221 0.72794562\n",
      " 0.72832326 0.72802115 0.72885196 0.72877644 0.72832326 0.72847432\n",
      "        nan 0.72885196 0.72877644 0.72885196 0.72885196 0.72870091\n",
      " 0.72877644 0.72877644 0.72877644        nan 0.72960725 0.72960725\n",
      " 0.72968278 0.72968278 0.72968278 0.72968278 0.72968278 0.72960725\n",
      "        nan 0.73172205 0.73172205 0.73134441 0.731571   0.73179758\n",
      " 0.73194864 0.73187311 0.73164653        nan 0.73066465 0.73036254\n",
      " 0.73126888 0.73096677 0.73126888 0.73066465 0.73194864 0.73134441\n",
      "        nan 0.73172205 0.73164653 0.73164653 0.73172205 0.73141994\n",
      " 0.73164653 0.73164653 0.73164653        nan 0.73240181 0.73255287\n",
      " 0.73240181 0.73240181 0.73232628 0.73240181 0.73247734 0.73240181]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_params_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(1,10),\n",
    "    'min_samples_split': range(1,10),\n",
    "    'min_samples_leaf': range(1,5)\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    grid_params_dt,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "grid_search_dt.fit(X_train_vec, y_train)\n",
    "print(\"Decision Tree, Grid search best parameters:\", grid_search_dt.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03246ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87       620\n",
      "           1       0.89      0.23      0.37       240\n",
      "\n",
      "    accuracy                           0.78       860\n",
      "   macro avg       0.83      0.61      0.62       860\n",
      "weighted avg       0.80      0.78      0.73       860\n",
      "\n",
      "Confusion matrix \n",
      " [[613   7]\n",
      " [184  56]]\n",
      "\n",
      " Decision Tree Grid search, Accuracy Score: 0.7779069767441861\n"
     ]
    }
   ],
   "source": [
    "grid_pred_dt = grid_search_dt.predict(X_test_vec)\n",
    "report = classification_report(y_test, grid_pred_dt)\n",
    "matrix = confusion_matrix(y_test,grid_pred_dt)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc5_g=accuracy_score(y_test,grid_pred_dt)\n",
    "\n",
    "print(\"\\n Decision Tree Grid search, Accuracy Score:\" , acc5_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fee945",
   "metadata": {},
   "source": [
    "# 4.6. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09d1b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       620\n",
      "           1       0.81      0.44      0.57       240\n",
      "\n",
      "    accuracy                           0.82       860\n",
      "   macro avg       0.81      0.70      0.73       860\n",
      "weighted avg       0.81      0.82      0.79       860\n",
      "\n",
      "Confusion matrix \n",
      " [[596  24]\n",
      " [135 105]]\n",
      "\n",
      " Random Forest Classifier, Accuracy Score: 0.8151162790697675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf_fit = rf.fit(X_train_vec,y_train)\n",
    "y_pred_rf = rf.predict(X_test_vec)\n",
    "\n",
    "report = classification_report(y_test, y_pred_rf)\n",
    "matrix = confusion_matrix(y_test,y_pred_rf)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc6=accuracy_score(y_test,y_pred_rf)\n",
    "\n",
    "print(\"\\n Random Forest Classifier, Accuracy Score:\" , acc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d52b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99a25f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [100],\n",
       "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
       "                         'min_samples_split': [8, 10, 12],\n",
       "                         'n_estimators': [10]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params_rfc = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [100],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [10]\n",
    "}\n",
    "\n",
    "grid_search_rfc = GridSearchCV(estimator = rf, param_grid = grid_params_rfc, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_rfc.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf1f9bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84       620\n",
      "           1       0.00      0.00      0.00       240\n",
      "\n",
      "    accuracy                           0.72       860\n",
      "   macro avg       0.36      0.50      0.42       860\n",
      "weighted avg       0.52      0.72      0.60       860\n",
      "\n",
      "Confusion matrix \n",
      " [[620   0]\n",
      " [240   0]]\n",
      "\n",
      " K-NN Grid search, Accuracy Score: 0.7209302325581395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishaduwadi/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anishaduwadi/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anishaduwadi/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "grid_pred_rfc = grid_search_rfc.predict(X_test_vec)\n",
    "report = classification_report(y_test, grid_pred_rfc)\n",
    "matrix = confusion_matrix(y_test,grid_pred_rfc)\n",
    "\n",
    "print(\"Classification report\\n\", report)\n",
    "print(\"Confusion matrix \\n\", matrix)\n",
    "acc6_g=accuracy_score(y_test,grid_pred_rfc)\n",
    "\n",
    "print(\"\\n K-NN Grid search, Accuracy Score:\" , acc6_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff297ba",
   "metadata": {},
   "source": [
    "# 5. Comparison and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55e14fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdw0lEQVR4nO3de5gdVZ3u8e9rIHIHNa1CuCRqAMGBKE0A56AookFhoiNKGJUBGXOiRI/yoKKDiDjeQAdHAWNkEM9RCSKi0RMFRUHkogkYkHANEaENSnOVcE9454+qlmJnd/dOp6uTdL2f5+mn67Jq1W91165f1apdVbJNREQ017PWdgAREbF2JRFERDRcEkFERMMlEURENFwSQUREwyURREQ0XBJBRIckvUPSRR2Umy3pEzWsX5K+Kel+Sb8b7vqjuZT7CGKkSfoX4BhgZ+AhYBHwGdu/WZtxresk7QucA+xk++FhqG8C8EegWtdttneXtDXwdaAb2BqYaPv2NV1nrJtyRhAjStIxwJeBzwIvALYHzgCmrcWwBiVpg7UdA7ADcPtQksAg8W9le7PyZ/dy2lPAz4C3DiHOWM8kEcSIkbQlcBJwtO0f2H7Y9pO2f2z7w2WZZ0v6sqRl5c+XJT27nLefpB5JH5F0t6S7JL1Z0hsl3SLpPkkfr6zvREnfl3SupIckXSNp98r84yTdVs67QdJbKvOOkHS5pFMl3QecWE77TTlf5by7JT0o6TpJLyvnnS3pPyp1vUfSkjK+eZK2qcyzpJmSbi27fE6XpDZ/u6OAM4F9JC2X9KkO6z5a0q3Aravzv7L9V9tnAAtWZ7lYPyURxEjaB9gIuGCAMv8O7A1MBnYHpgDHV+a/sKxjPHAC8A3gncAewL7ACZJeVCk/DTgPeC7wXeCHkjYs591WLrMl8Cng22WXSJ+9gKXA84HPtMT5euBVwI7AVsChwL2tjZH0WuBzwNspulj+BMxtKXYQsGfZ3rcDb2itx/Z/AzOBK8sj9092WPeby3bs0lpnRJ8kghhJzwPusb1igDLvAE6yfbftXood9Lsq85+kuJ7wJMVObxzwX7Yfsr0YWAzsVil/te3vl+X/kyKJ7A1g+zzby2w/ZftciqPmKZVll9n+qu0Vth9tifNJYHOK6xyyfaPtu/ppz1m2r7H9OPAxiqP6CZUyn7f9gO07gF9RJMFOdFL352zf1yb+qnskPVD+HNvhumMUSSKIkXQvMG6Q/uptKI5s+/ypnPb3OmyvLIf7dm5/rcx/FNisMn5n34Dtp4CevvokHS5pUd9OEHgZRWJZZdlWtn8JnAacDvxV0hxJWwzWHtvLKf4O4ytl/lIZfqQl/oF0Une/bagYZ3ur8ueLHa47RpEkghhJVwKPUXRX9GcZxUXRPtuX04Zqu74BSc8CtgWWSdqBoltpFvA821sB1wPV/vkBv1Jn+yu29wB2pegi+nCbYs9oj6RNKc6M/jyUxgyh7nwtMAaVRBAjxvaDFP36p5cXeTeRtKGkAyWdXBY7BzheUpekcWX5b6/BaveQ9M/lWcgHgceBq4BNKXaSvQCSjqQ4I+iIpD0l7VVeb3iYIsGtbFP0u8CRkiaXF70/C/x2mL6KWWfdSNoIeHY5+uxyPEahJIIYUbb/k+IeguMpdsJ3UhyV/7As8h/AQuA64A/ANeW0ofoRxYXc+ymuNfxz+U2lG4AvUZyl/BX4B+Dy1ah3C4ozivspumfuBVbpVrF9MfAJ4HzgLuDFwPShNmak6i49Ciwvh2/i6a64GGVyQ1mMWpJOBF5i+51rO5aIdVnOCCIiGi6JICKi4dI1FBHRcDkjiIhouHXhQVqrZdy4cZ4wYcLaDiMiYr1y9dVX32O7q9289S4RTJgwgYULF67tMCIi1iuS/tTfvHQNRUQ0XBJBRETDJRFERDRcEkFERMMlEURENFwSQUREwyURREQ0XBJBRETD1ZoIJE2VdLOkJZKOazN/S0k/lnStpMXly0EiImIE1XZnsaQxFO9zPYDiPbELJM0rXwjS52jgBtsHS+oCbpb0HdtP1BVXrNtO/fktazuEjnzogB3XdggRw6bOM4IpwBLbS8sd+1xgWksZA5tLEsULu+8DVtQYU0REtKjzWUPjKV5D2KcH2KulzGnAPIqXcG8OHGr7qdaKJM0AZgBsv/32Qw4oR5sREauq84xAbaa1vvzgDcAiYBtgMnCapC1WWcieY7vbdndXV9uH50VExBDVmQh6gO0q49tSHPlXHQn8wIUlwB+BnWuMKSIiWtSZCBYAkyRNlDQWmE7RDVR1B7A/gKQXADsBS2uMKSIiWtR2jcD2CkmzgAuBMcBZthdLmlnOnw18Gjhb0h8oupI+avueumKKiIhV1fpiGtvzgfkt02ZXhpcBr68zhoiIGNh694ayiFi78u270SePmIiIaLgkgoiIhksiiIhouCSCiIiGy8Xi9Vwu3K378j+KdV3OCCIiGi6JICKi4ZIIIiIaLokgIqLhkggiIhouiSAiouGSCCIiGi6JICKi4ZIIIiIaLncWR0TjNf3u75wRREQ0XK2JQNJUSTdLWiLpuDbzPyxpUflzvaSVkp5bZ0wREfFMtSUCSWOA04EDgV2AwyTtUi1j+xTbk21PBj4GXGr7vrpiioiIVdV5RjAFWGJ7qe0ngLnAtAHKHwacU2M8ERHRRp2JYDxwZ2W8p5y2CkmbAFOB8/uZP0PSQkkLe3t7hz3QiIgmqzMRqM0091P2YODy/rqFbM+x3W27u6ura9gCjIiIehNBD7BdZXxbYFk/ZaeTbqGIiLWizkSwAJgkaaKksRQ7+3mthSRtCbwa+FGNsURERD9qu6HM9gpJs4ALgTHAWbYXS5pZzp9dFn0LcJHth+uKJSIi+lfrncW25wPzW6bNbhk/Gzi7zjgiIqJ/ubM4IqLhkggiIhouiSAiouGSCCIiGi6JICKi4ZIIIiIaLokgIqLhkggiIhouiSAiouGSCCIiGi6JICKi4ZIIIiIaLokgIqLhkggiIhouiSAiouGSCCIiGq7WRCBpqqSbJS2RdFw/ZfaTtEjSYkmX1hlPRESsqrY3lEkaA5wOHEDxIvsFkubZvqFSZivgDGCq7TskPb+ueCIior06zwimAEtsL7X9BDAXmNZS5l+AH9i+A8D23TXGExERbdSZCMYDd1bGe8ppVTsCz5F0iaSrJR3eriJJMyQtlLSwt7e3pnAjIpqpzkSgNtPcMr4BsAfwJuANwCck7bjKQvYc2922u7u6uoY/0oiIBqvtGgHFGcB2lfFtgWVtytxj+2HgYUm/BnYHbqkxroiIqKjzjGABMEnSREljgenAvJYyPwL2lbSBpE2AvYAba4wpIiJa1HZGYHuFpFnAhcAY4CzbiyXNLOfPtn2jpJ8B1wFPAWfavr6umCIiYlV1dg1hez4wv2Xa7JbxU4BT6owjIiL6lzuLIyIaLokgIqLhkggiIhouiSAiouGSCCIiGi6JICKi4ZIIIiIaLokgIqLhkggiIhouiSAiouGSCCIiGi6JICKi4ZIIIiIaLokgIqLhkggiIhouiSAiouGSCCIiGq7WRCBpqqSbJS2RdFyb+ftJelDSovLnhDrjiYiIVdX2qkpJY4DTgQOAHmCBpHm2b2gpepntg+qKIyIiBjboGYGkgyQN5cxhCrDE9lLbTwBzgWlDqCciImrUyQ5+OnCrpJMlvXQ16h4P3FkZ7ymntdpH0rWSfipp13YVSZohaaGkhb29vasRQkREDGbQRGD7ncDLgduAb0q6stwxbz7IompXXcv4NcAOtncHvgr8sJ8Y5tjutt3d1dU1WMgREbEaOurysf034HyK7p2tgbcA10h6/wCL9QDbVca3BZa11mt7eTk8H9hQ0rjOw4+IiDXVyTWCgyVdAPwS2BCYYvtAYHfg2AEWXQBMkjRR0liKLqZ5LXW/UJLK4SllPPcOqSURETEknXxr6G3AqbZ/XZ1o+xFJ7+5vIdsrJM0CLgTGAGfZXixpZjl/NnAI8F5JK4BHgem2W7uPIiKiRp0kgk8Cd/WNSNoYeIHt221fPNCCZXfP/JZpsyvDpwGnrVbEERExrDq5RnAe8FRlfGU5LSIiRoFOEsEG5X0AAJTDY+sLKSIiRlIniaBX0j/1jUiaBtxTX0gRETGSOrlGMBP4jqTTKO4NuBM4vNaoIiJixAyaCGzfBuwtaTNAth+qP6yIiBgpHT10TtKbgF2Bjcqv/WP7pBrjioiIEdLJDWWzgUOB91N0Db0N2KHmuCIiYoR0crH4lbYPB+63/SlgH5756IiIiFiPdZIIHit/PyJpG+BJYGJ9IUVExEjq5BrBjyVtBZxC8bRQA9+oM6iIiBg5AyaC8oU0F9t+ADhf0k+AjWw/OBLBRURE/QbsGrL9FPClyvjjSQIREaNLJ9cILpL01r7HRUdExOjSyTWCY4BNgRWSHqP4Cqltb1FrZBERMSI6ubN4sFdSRkTEemzQRCDpVe2mt76oJiIi1k+ddA19uDK8ETAFuBp47WALSpoK/BfFG8rOtP35fsrtCVwFHGr7+x3EFBERw6STrqGDq+OStgNOHmw5SWOA04EDKF5kv0DSPNs3tCn3BYpXWkZExAjr5FtDrXqAl3VQbgqwxPbS8mU2c4Fpbcq9HzgfuHsIsURExBrq5BrBVynuJoYicUwGru2g7vEU7y7o0wPs1VL3eOAtFN1Me3ZQZ0REDLNOrhEsrAyvAM6xfXkHy7W778At418GPmp75UC3KUiaAcwA2H777TtYdUREdKqTRPB94DHbK6Ho05e0ie1HBlmuh2c+pXRbYFlLmW5gbpkExgFvlLTC9g+rhWzPAeYAdHd3tyaTiIhYA51cI7gY2LgyvjHwiw6WWwBMkjRR0lhgOjCvWsD2RNsTbE+gSDjva00CERFRr07OCDayvbxvxPZySZsMtpDtFZJmUXwbaAxwlu3FkmaW82cPNeiIiBg+nSSChyW9wvY1AJL2AB7tpHLb84H5LdPaJgDbR3RSZ0REDK9OEsEHgfMk9fXvb03x6sqIiBgFOrmhbIGknYGdKL4JdJPtJ2uPLCIiRkQnL68/GtjU9vW2/wBsJul99YcWEREjoZNvDb2nfEMZALbvB95TW0QRETGiOkkEz6q+lKZ8NtDY+kKKiIiR1MnF4guB70maTXFn8Ezgp7VGFRERI6aTRPBRisc7vJfiYvHvKb45FBERo8CgXUPlC+yvApZSPBJif+DGmuOKiIgR0u8ZgaQdKR4LcRhwL3AugO3XjExoERExEgbqGroJuAw42PYSAEkfGpGoIiJixAzUNfRW4C/AryR9Q9L+tH+0dERErMf6TQS2L7B9KLAzcAnwIeAFkr4m6fUjFF9ERNSsk4vFD9v+ju2DKN4psAg4ru7AIiJiZKzWO4tt32f767ZfW1dAERExsoby8vqIiBhFkggiIhouiSAiouFqTQSSpkq6WdISSatcYJY0TdJ1khZJWijpf9UZT0RErKqTZw0NSfmU0tOBA4AeYIGkebZvqBS7GJhn25J2A75H8XXViIgYIXWeEUwBltheavsJYC4wrVrA9nLbLkc3pXi6aUREjKA6E8F44M7KeE857RkkvUXSTcD/B97driJJM8quo4W9vb21BBsR0VR1JoJ2j6NY5Yi/vIN5Z+DNwKfbVWR7ju1u291dXV3DG2VERMPVmQh6gO0q49sCy/orbPvXwIsljasxpoiIaFFnIlgATJI0UdJYikdaz6sWkPSSvtdgSnoFxSsw760xpoiIaFHbt4Zsr5A0i+JVl2OAs2wvljSznD+b4gmnh0t6EngUOLRy8TgiIkZAbYkAwPZ8YH7LtNmV4S8AX6gzhoiIGFjuLI6IaLgkgoiIhksiiIhouCSCiIiGSyKIiGi4JIKIiIZLIoiIaLgkgoiIhksiiIhouCSCiIiGSyKIiGi4JIKIiIZLIoiIaLgkgoiIhksiiIhouCSCiIiGSyKIiGi4WhOBpKmSbpa0RNJxbea/Q9J15c8VknavM56IiFhVbYlA0hjgdOBAYBfgMEm7tBT7I/Bq27sBnwbm1BVPRES0V+cZwRRgie2ltp8A5gLTqgVsX2H7/nL0KmDbGuOJiIg26kwE44E7K+M95bT+HAX8tN0MSTMkLZS0sLe3dxhDjIiIOhOB2kxz24LSaygSwUfbzbc9x3a37e6urq5hDDEiIjaose4eYLvK+LbAstZCknYDzgQOtH1vjfFEREQbdZ4RLAAmSZooaSwwHZhXLSBpe+AHwLts31JjLBER0Y/azghsr5A0C7gQGAOcZXuxpJnl/NnACcDzgDMkAayw3V1XTBERsao6u4awPR+Y3zJtdmX434B/qzOGiIgYWO4sjohouCSCiIiGSyKIiGi4JIKIiIZLIoiIaLgkgoiIhksiiIhouCSCiIiGSyKIiGi4JIKIiIZLIoiIaLgkgoiIhksiiIhouCSCiIiGSyKIiGi4JIKIiIarNRFImirpZklLJB3XZv7Okq6U9LikY+uMJSIi2qvtDWWSxgCnAwdQvMh+gaR5tm+oFLsP+ADw5rriiIiIgdV5RjAFWGJ7qe0ngLnAtGoB23fbXgA8WWMcERExgDoTwXjgzsp4TzlttUmaIWmhpIW9vb3DElxERBTqTARqM81Dqcj2HNvdtru7urrWMKyIiKiqMxH0ANtVxrcFltW4voiIGII6E8ECYJKkiZLGAtOBeTWuLyIihqC2bw3ZXiFpFnAhMAY4y/ZiSTPL+bMlvRBYCGwBPCXpg8Autv9WV1wREfFMtSUCANvzgfkt02ZXhv9C0WUUERFrSe4sjohouCSCiIiGSyKIiGi4JIKIiIZLIoiIaLgkgoiIhksiiIhouCSCiIiGSyKIiGi4JIKIiIZLIoiIaLgkgoiIhksiiIhouCSCiIiGSyKIiGi4JIKIiIZLIoiIaLhaE4GkqZJulrRE0nFt5kvSV8r510l6RZ3xRETEqmpLBJLGAKcDBwK7AIdJ2qWl2IHApPJnBvC1uuKJiIj26jwjmAIssb3U9hPAXGBaS5lpwP914SpgK0lb1xhTRES0qPPl9eOBOyvjPcBeHZQZD9xVLSRpBsUZA8BySTcPb6hrZBxwz3BWeMxwVjY0o61No609MPraNNraA+tem3bob0adiUBtpnkIZbA9B5gzHEENN0kLbXev7TiG02hr02hrD4y+No229sD61aY6u4Z6gO0q49sCy4ZQJiIialRnIlgATJI0UdJYYDowr6XMPODw8ttDewMP2r6rtaKIiKhPbV1DtldImgVcCIwBzrK9WNLMcv5sYD7wRmAJ8AhwZF3x1Gid7LJaQ6OtTaOtPTD62jTa2gPrUZtkr9IlHxERDZI7iyMiGi6JICKi4RqXCCQtr6HOlZIWSbpe0o8lbTXc61jddUvaRtL3+1nmEkkdf61N0n6SHpT0e0k3SfriMIW/xiT9u6TF5SNKFkn6qaTPtZSZLOnGcvh2SZe1zF8k6fqRjLud6rYp6Y2SbpW0fUuZ2yWdXxk/RNLZ5fARkp6StFtl/vWSJtQQa992t1jStZKOkbRG+xNJR5Z1LpL0hKQ/lMOfH8Z4h/UzWv7NT2szve8z09eeXwzH+gaIYZs1qaNxiaAmj9qebPtlwH3A0Wt73baX2T5kGNdzme2XAy8HDpL0j8NY95BI2gc4CHiF7d2A1wGfBw5tKTod+G5lfHNJ25V1vHQkYl0dkvYHvgpMtX1HmyLdknbtZ/Ee4N9rC+5pfdvdrsABFF/6+OSaVGj7m2Wdkym+Rv6acvzvzykrH12zJvGO5Gf0sr722H5dpwsNoY1HAEkEa6o8YryqPKq8QNJzyul7ltOulHRKh0eNV1LcHY2kF0v6maSrJV0maefK9KskLZB00jCepVTXPaEvXkkbS5pbtuVcYONK24+SdEt5lvCNdkc3VbYfBRZV1vP68u9zjaTzJG1WTn9jefbwGxUPFvzJMLWxamvgHtuPl7HdY/tS4AFJ1bvY307xiJM+3+PpZHEYcE4NsQ2JpH2BbwBvsn1bP8W+CHy8n3k/AXaVtFMd8bVj+26KO/9nqTCm/LwsKLe5/91XVtJHyiP9azs90pe0vPyc/BbYR9I7Jf2uPNL+et+Os79tsY3q52SKpCtUnO1e0fd3K4+yf1B+fm+VdHIlniPLz8ylwGodEEk6rGz/9ZK+sDptLH/OLpf9g6QPSToE6Aa+U5bduN+VD8R2o36A5W2mXQe8uhw+CfhyOXw98Mpy+PPA9QPVSfE12fMojuQALgYmlcN7Ab8sh38CHFYOz2wX0+q2p826J/TFS3Fn+lnl8G7AinLj2Qa4HXgusCFwGXBam3XsB/ykHH4OcDXwQopb6H8NbFrO+yhwArARxaNDJpbTz+lbfpj/l5tRJKVbgDMq/8MPA6eWw3sDCyrL3A7sCFxRjv+e4qGIbf+3I7xtPklxtLrbAGVuB14A3Ai8BDgEOLucdwRwGnA48K3KNjyhhljbfY7uL2ObARxfTns2sBCYSPGQySuATcp5zx2knePKYQNvL4dfCvwY2LAcP6Nsb9ttsYPPyRbABuXw64DzK3/LpcCW5fb8J4qbX7cG7gC6gLHA5QN8Zh4st89FFGdp21SW3QD4JfDm1WjjHsDPK+vYqvx9CdC9Jv/Pxp8RSNqS4g96aTnpW8Cryj7EzW1fUU7/brvlSxtLWgTcS7FT/Xl5NPJK4Lxy3tcpNiKAfSg2xsHq7cQq625T5lXAtwFsX0eR+KB4MOCltu+z/WQlpnb2lXQd8BeKnfpfKHayuwCXlzH8K8XzTHYGltr+Y7lsLUfctpdTfDhmAL3AuZKOoDj6P0RFn/X0Nuu/D7hf0nSKHeojdcQ3BE9S7CiPGqTcSuAU4GP9zP8usLekicMYWyf6HhnzeoobRRcBvwWeR/GE4dcB37T9CIDt+zqsdyXQd11kf4r/+YKy/v2BF9H/ttinv8/JlhSf0euBU4Fql9vFth+0/RhwQ1nfXsAltntdPEzz3AHirnYNfQbYs7LsCuA7FJ/NTtu4FHiRpK9Kmgr8beA/W+canwgG0O45SP151EW/5g4URwlHU/xtH6hsCJNt19Ef3W7d7bS7YWR12niZi374fwDeK2lyufzPK+3bxfZRq1nvGrG90vYltj8JzALeavtOiiPKVwNvpegKanUuxWPS15luIeApim6sPSV9vOwK6LvYeFJL2f9HsRPZvrWScifzJYqj4hEh6UUUO7O7Kf7/769sFxNtX1ROH8qNS4/ZXtm3Koqznb66d7J9Iv1vi336+5x8GviVi2sHB1Mc/fd5vDK8kqdvwB3qzVcDfS4GbaPt+4HdKc4AjgbOHGIcq2h8IrD9IMXR4b7lpHdRHCXfDzyk4tEXUBxZdlLXB4BjgUeBP0p6G/z9JTy7l0WvothBdVTvarTjA8CxkjZsmf1r4B1lHC+j6B4C+B3waknPkbRBJaaB1nML8DmKncxVwD9KeklZ9yaSdgRuojhymVAu1nrxdlhI2knSpMqkyRSn8FDs4E8FbrPd02bxC4CTKe58X2eUR8sHUfy/jqjsDE5oKfckRfs+2E9VZ1McgXfVF21BUhcwm6KLxBR/0/f2bYeSdpS0KXAR8G5Jm5TTnzuE1V1Mcbb3/L46JO1A/9viM7T5nGwJ/LmcfUQH6/8tsJ+k55XLv201Yv8txedtXHld4zDg0jbl2rZR0jjgWbbPBz4B9L3I6yFg89WIYxVNTASbSOqp/BxDcRp5Stn1MZniOgEUp+hzJF1JkaUfhL9/NXN+u8pt/x64lmIH/w7gKEnXAot5+n0MHwSOkfQ7iu6iB/uWL08Fh6Rl3VVfAzYr2/cRigSA7T8Dn6XYQH9Bcfrb18Z/anMU2mc2xdHoZhQfnnPKuq8CdnZxQfl9wM8k/Qb4a7WNw2gz4FuSbijXvwtwYjnvPIrT/LntFrT9kO0vlKf365Syy2QqcLyk1nd4VP03/TwmpmzXV4DnD3+EQNnVImkxxbZzEfCpct6ZFNvSNWWXy9cp+uF/RvF8sYXldn4sgKSZKh89MxjbNwDHAxeV//OfA1vb7qXNtthPHdXPycnA5yRdTnH9YLD130WxjV1ZtvuavnmDfGb6lv0Y8Kty/dfY/lGnbaS4wH1J+bc7m6e7Bs8GZq/JxeI8YmIAkjYr+6FR8arNrW3/n2GodxOKU1WX/dSH2R7oA1+bvjaWZwQXUFxUvmAY6xVFF8yttk9d03ojYvjV+T6C0eBNkj5G8Xf6E52dOnZiD+C0cif5APDuYap3KE6U9DqKvtGLgB8OU73vkfSvFP2xv6c4KoyIdVDOCCIiGq6J1wgiIqIiiSAiouGSCCIiGi6JICKi4ZIIIiIa7n8AYeJ+mQkl08wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ('Log.Reg.', 'Ridg.Reg','SVM','K-NN','Dec.Tree','Rand.Forest')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [acc1_g,acc2_g,acc3_g,acc4_g,acc5_g,acc6_g]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparision for F1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b508e7a",
   "metadata": {},
   "source": [
    "Hence, among all SVM and Logistic Regression have higher accuracy as compared to other ML algorithms. Tuning the range of the grid search parameters of above used ML algorithms and/or using other ML models could help to further improve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec3e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
